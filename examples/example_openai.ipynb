{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyI6TvdzHvkD",
        "outputId": "f7b01eb4-93f7-47c9-a2c3-dfdf19494006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Installations\n",
        "%pip install -q openai\n",
        "%pip install -q git+https://github.com/PYPE-AI-MAIN/pypeprompts.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zRhTaQpjG2if"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pypeprompts import PromptAnalyticsTracker\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lONrBJ8wH3Aa"
      },
      "outputs": [],
      "source": [
        "# Initial OpenAI client\n",
        "client = OpenAI(api_key=\"sk-proj-xxxx\")\n",
        "\n",
        "# Initialize the PromptAnalyticsTracker\n",
        "tracker = PromptAnalyticsTracker(\n",
        "    name=\"Google collab tracker\",\n",
        "    api_key=\"get_api_key_from_pype_app\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rHVpusgEH_F0"
      },
      "outputs": [],
      "source": [
        "# Usage\n",
        "@tracker.track_prompt\n",
        "def generate_text(prompt: str) -> str:\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",  # Updated to a valid model name\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\",\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "        )\n",
        "        print(\"Total tokens:\", response.usage.total_tokens)\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling OpenAI API: {e}\")\n",
        "        return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybdC9kXAICxr",
        "outputId": "a64ccd42-730f-4804-e189-ca1b2163a77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total tokens: 176\n",
            "Analytics data submitted successfully.\n"
          ]
        }
      ],
      "source": [
        "result = generate_text(\"Write a short poem about Python programming.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
